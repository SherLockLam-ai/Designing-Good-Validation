{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2v0vIN7H3_Zo"
   },
   "source": [
    "### Bias, Variance, and Irreducible Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRyzwbsD23sv"
   },
   "source": [
    "Hiệu suất của một model trong một task có thể được mô tả dưới dạng prediction error trên tất cả các mẫu không được sử dụng trong quá trình training model. Chúng ta ký hiệu là:\n",
    "$$ Error(Model) $$\n",
    "\n",
    "Model error bao gồm 3 thành phần: variance, bias và irreducible error\n",
    "$$ Error(Model) = Variance(Model) + Bias(Model) + Variance(Irreducible Error) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWq50WQ638S6"
   },
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETmYimd44DLC"
   },
   "source": [
    "Bias ước lượng mức độ chặt chẽ của model có thể nắm bắt được sự ánh xạ giữa input và output. \n",
    "- Model với high bias sẽ **không** có sự liên kết chặt chẽ giữa input và output.\n",
    "- Model với low bias sẽ liên kết chặt chẽ giữa input và output\n",
    "\n",
    "Một số đặc điểm của một model high bias bao gồm:\n",
    "- Không nắm bắt được xu hướng của dữ liệu (data trend)\n",
    "- Tiềm năng dẫn tới hiện tượng underfitting \n",
    "- Tổng quát hóa/đơn giản hóa một cách quá mức\n",
    "- High error rate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_6VyIGf_03a"
   },
   "source": [
    "### Variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UvOQ5lV_2M8"
   },
   "source": [
    "Variance của mô hình là mức độ hiệu suất của mô hình thay đổi khi nó fit trên các training data khác nhau.\n",
    "\n",
    "Nói một cách đơn giản, variance là độ biến thiên trong dự đoán của model. Variance xuất hiện từ các mô hình phức tạp với số lượng lớn features.\n",
    "\n",
    "- Model với high bias => low variance\n",
    "- Model với high variance => low bias \n",
    "\n",
    "Một số đặc điểm của một model high variance bao gồm:\n",
    "- Dataset chứa nhiễu\n",
    "- Tiềm năng dẫn tới hiện tượng overfitting\n",
    "- Model quá phức tạp\n",
    "- Cố gắng fit tất cả các điểm dữ liệu trong dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz20_EnuB0Fz"
   },
   "source": [
    "### Irreducible Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7eNuKMUB8X_"
   },
   "source": [
    "Error Model bao gồm reducible error và irreducible error.\n",
    "\n",
    "Reducible error là thành phần chúng ta có thể cải thiện - số lượng mà chúng ta sẽ cố gắng giảm trong quá trình training model trên training test và mục tiêu đưa error càng gần 0 càng tốt\n",
    "\n",
    "\n",
    "Irreducible error là lỗi mà chúng ta không thể loại bỏ với mô hình của mình hoặc với bất kỳ mô hình nào. Lỗi do các yếu tố nằm ngoài tầm kiểm soát của chúng ta, ví dụ như nhiễu trong quá trình thống kê trong tập dữ liệu quan sát. \n",
    "\n",
    "\"It is important to keep in mind that the irreducible error will always provide an upper bound on the accuracy of our prediction for Y. This bound is almost always unknown in practice\" - An Introduction to Statistical Learning: with Applications in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go1oim3Lo27N"
   },
   "source": [
    "### Bias-Variance Trade-off "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_G1A5Rlo6pm"
   },
   "source": [
    "Bias và Variance luôn có sự kết nối mật thiết với nhau. Trong điều kiện lý tưởng nhất là chúng ta xây dựng được một mô hình với low bias-low variance. Và trong thực tế để xây dựng được model như vậy sẽ rất khó khăn. \n",
    "\n",
    "Giảm bias có thể dễ dàng đạt được bằng cách tăng variance. Ngược lại, có thể dễ dàng giảm variance bằng cách tăng bias. Đây là một quá trình phức tạp trong việc chọn và tinh chỉnh model, chúng ta cần có sự đánh đổi giữa bias và variance.\n",
    "\n",
    "Chúng ta có thể chọn một model cơ bản dựa trên bias hoặc variance. Trong Machine Learning một số model cơ bản như Linear Regression và Logistic Regression, thường cho high bias và low variance. Một số model phức tạp hơn như, Random Forest, thường thường cho low bias nhưng high variance.\n",
    "\n",
    "Chúng ta có thể config model dựa trên Bias-Variance. Ví dụ đối với K-Nearest Neighbors chúng ta thường sử dụng tham số k để kiểm soát sự đánh đổi giữa bias và variance. Với giá k trị nhỏ, dẫn đến low bias và high variance, trong khi giá trị k lớn, dẫn đến high bias và low variance. Tương tự với C, kernel, Gamma trong SVM.\n",
    "\n",
    "Chúng ta vẫn luôn phẩi kiểm tra những config khác nhau của model để kiểm tra xem đâu là bộ config tốt nhất trên tập dữ liệu đã được xác định."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGSi1iEebCGd"
   },
   "source": [
    "### Calculate the Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rFn0opv8bFGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (1.15.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (2.2.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (3.10.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.0/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DiLKWWkzcm3n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (1.15.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (2.2.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (3.10.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fptsh\\downloads\\aio\\.venv\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-xbfCcdbIIK",
    "outputId": "ef519b4e-fdf7-4fc6-cc4a-ab6a0976eac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 22.724\n",
      "Bias: 21.531\n",
      "Variance: 1.193\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df  = pd.read_csv(url, header=None)\n",
    "\n",
    "# split the data\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression \n",
    "model = LinearRegression()\n",
    "\n",
    "# Calculate bias and variance\n",
    "mse, bias, var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
    "\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJkNtHffcyEk",
    "outputId": "a6a8f2c7-d68f-43d7-d818-b88e73fa8b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 25.687\n",
      "Bias: 24.638\n",
      "Variance: 1.049\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # thay đổi train_test_split_rate\n",
    "\n",
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "\n",
    "# Calculate bias and variance\n",
    "mse, bias, var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
    "\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJpNaKFfc7RF",
    "outputId": "15f8b222-894b-4e6d-ebf3-487eeda38f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 23.415\n",
      "Bias: 21.808\n",
      "Variance: 1.607\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42) # thay đổi train_test_split_rate\n",
    "\n",
    "# Linear Regression \n",
    "model = LinearRegression()\n",
    "\n",
    "# Calculate bias and variance\n",
    "mse, bias, var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
    "\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
