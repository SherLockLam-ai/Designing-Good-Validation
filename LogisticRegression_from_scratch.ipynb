{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s3Ak7WR22Gu-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4LpT0SMA2Rlf"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, X, lr=0.01, epochs=1000):\n",
        "    \"\"\"\n",
        "      X: input tensor\n",
        "      lr: learning rate\n",
        "      epochs: number of times the model iterates over complete dataset\n",
        "      weights: params learned during training\n",
        "      bias: param learned during training\n",
        "    \"\"\"\n",
        "    self.lr = lr\n",
        "    self.epochs = epochs\n",
        "    self.m, self.n = X.shape\n",
        "    self.weights = torch.zeros((self.n, 1), dtype=torch.double)\n",
        "    self.bias = 0\n",
        "  \n",
        "  def sigmoid(self, z):\n",
        "    \"\"\"\n",
        "      z: latent variable presents (wx + b)\n",
        "      return: the real value between 0 and 1 representing probability score\n",
        "    \"\"\"\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "  \n",
        "  def loss(self, yhat):\n",
        "    \"\"\"\n",
        "      yhat: estimated y\n",
        "    \"\"\"\n",
        "    return -(1/self.m) * torch.sum(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) \n",
        "  \n",
        "  def gradient(self, y_predict):\n",
        "    \"\"\"\n",
        "      y_predict: estimate y\n",
        "      return: gradient is calculated to find how much change is required in parameters to reduce the loss.\n",
        "    \"\"\"\n",
        "    dw = 1/self.m * torch.mm(X.T, (y_predict-y))\n",
        "    db = 1/self.m * torch.sum(y_predict-y)\n",
        "\n",
        "    return dw, db\n",
        "  \n",
        "  def run(self, X, y):\n",
        "    \"\"\"\n",
        "      X: input tensor\n",
        "      y: output tensor\n",
        "      y_predict: Predict tensor\n",
        "      cost: Different between ground truth and predicted\n",
        "      dw, dc: weight and bias update for weight tensor and bias tensor\n",
        "      return update weights and bias\n",
        "    \"\"\"\n",
        "    for epoch in range(1, self.epochs+1):\n",
        "      y_predict = self.sigmoid(torch.mm(X, self.weights) + self.bias)\n",
        "      cost = self.loss(y_predict)\n",
        "      dw, db = self.gradient(y_predict)\n",
        "\n",
        "      self.weights -= self.lr * dw \n",
        "      self.bias -= self.lr * db\n",
        "\n",
        "      if epoch % 100 == 0:\n",
        "        print(f\"Cost after iteration {epoch}: {cost}\")\n",
        "    \n",
        "    return self.weights, self.bias\n",
        "  \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "      X: input tensor\n",
        "      y_predict_label: Converts float value to int/bool true(1) or false(0)\n",
        "      return output labels as 0 and 1\n",
        "    \"\"\"\n",
        "    y_predict = self.sigmoid(torch.mm(X, self.weights) + self.bias)\n",
        "    y_predict_labels = y_predict > 0.5\n",
        "\n",
        "    return y_predict_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XD9f3vXr7lJU"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "X, y = make_blobs(n_samples=1000, centers=2)\n",
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VFv9Gg4Y79x5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after iteration 100: 0.13652053582494666\n",
            "Cost after iteration 200: 0.07897589847913174\n",
            "Cost after iteration 300: 0.05727669762680107\n",
            "Cost after iteration 400: 0.045709852603239405\n",
            "Cost after iteration 500: 0.03844734654910672\n",
            "Cost after iteration 600: 0.03342750465086123\n",
            "Cost after iteration 700: 0.029731001155634148\n",
            "Cost after iteration 800: 0.0268839998808286\n",
            "Cost after iteration 900: 0.024616599320132247\n",
            "Cost after iteration 1000: 0.022763347359388245\n",
            "Accuracy: 1\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(X)\n",
        "w, b = model.run(X, y)\n",
        "y_predict = model.predict(X)\n",
        "\n",
        "print(f\"Accuracy: {torch.sum(y == y_predict) // X.shape[0]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
